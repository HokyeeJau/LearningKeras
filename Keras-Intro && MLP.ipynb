{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense\n",
    "keras.layers.Dense(units, 神经元数量/输出数目\n",
    "                   activation=None, 使用的激活函数m\n",
    "                   use_bias,是否添加偏置项\n",
    "                   kernel_initializer='glorot_uniform', 权重初始化方法\n",
    "                   bias_initializer='zeros', 偏置值初始化\n",
    "                   kernel_regularizer=None, 权重规范化函数\n",
    "                   bias_regularizer=None, 运用到偏置向的的正则化函数\n",
    "                   activity_regularizer=None, 输出的规范化方法\n",
    "                   kernel_constraint=None, 权值矩阵的约束函数 \n",
    "                   bias_constraint=None) 运用到偏置向量的约束函数\n",
    "### Activation\n",
    "keras.layers.Activation(activation)\n",
    "预定义激活函数：\n",
    "keras.activations.softmax(x,axis=-1) #通过不同的axis，numpy会沿着不同的方向进行操作：如果不设置，那么对所有的元素操作；如果axis=0，则沿着纵轴进行操作；axis=1，则沿着横轴进行操作\n",
    "keras.layers.Activation(activation)\n",
    "\n",
    "### Dropout\n",
    "keras.layers.Dropout(rate, noise_shape=None, seed=None)\n",
    "\n",
    "### Flatten\n",
    "keras.layers.Flatten(data_format=None\n",
    "\n",
    "### Input\n",
    "keras.engine.input_layer.Input(shape, batch_size, name, dtype, sparse, tensor)\n",
    "\n",
    "### Reshape\n",
    "keras.layers.Reshape(target_shape)\n",
    "\n",
    "### Permute\n",
    "keras.layers.Permute(dims)\n",
    "根据给定的模式置换输入的维度\n",
    "\n",
    "### RepeatVector\n",
    "keras.utils.RepeatVector(n)\n",
    "将输入重复n次\n",
    "\n",
    "### Lambda\n",
    "keras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)\n",
    "\n",
    "### ActivityRegularization\n",
    "keras.layers.ActivityRegularization(l1=0.0, l2=0.0)\n",
    "\n",
    "### Masking\n",
    "keras.layers.Masking(mask_value=0.0)\n",
    "\n",
    "### SpatialDropout1D\n",
    "keras.layers.SpatialDropout1D(rate)\n",
    "此版本的功能与 Dropout 相同，但它会丢弃整个 1D 的特征图而不是丢弃单个元素。如果特征图中相邻的帧是强相关的（通常是靠前的卷积层中的情况），那么常规的 dropout 将无法使激活正则化，且导致有效的学习速率降低。在这种情况下，SpatialDropout1D 将有助于提高特征图之间的独立性，应该使用它来代替 Dropout。\n",
    "\n",
    "### SpatialDropout2D\n",
    "keras.layers.SpatialDrouput2D(rate, data_format=None)\n",
    "\n",
    "### SpatialDropout3D\n",
    "keras.layers.SpatialDrouput3D(rate, data_format=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# The sequential model is a linear stack of layers\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784, )),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also simply add layers via the .add() method\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ever need to specify a fixed batch size for your inputs, you can pass batch_size argument to a layer.\n",
    "if you pass both batch_size and input_shape(6,8) to a layer, it will then expect every batch of inputs to have the batch shape(32, 6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# As such, the following snippets are strictly equivalent\n",
    "model.add(Dense(32, input_shape=(784, )))\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation\n",
    "- an optimizer. this could be the string identifier of an exisiting optimizer(such as rmsprop or adagrad), or an instance of the Optimizer class.\n",
    "- A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an exisiting loss function.(such as categorical_crossentropy or mse), or it can be objective function. \n",
    "- A list of metrics. for any classification problems you will want to set this to metrics=['accuracy']. a metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# for a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# for a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='mse')\n",
    "\n",
    "# for custom metrics\n",
    "import keras.backend as K\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.2456 - accuracy: 0.9244 - val_loss: 0.1227 - val_accuracy: 0.9612\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1037 - accuracy: 0.9691 - val_loss: 0.0930 - val_accuracy: 0.9720\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0753 - accuracy: 0.9780 - val_loss: 0.0820 - val_accuracy: 0.9751\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.0782 - val_accuracy: 0.9775\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0745 - val_accuracy: 0.9805\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 0.0705 - val_accuracy: 0.9803\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0380 - accuracy: 0.9886 - val_loss: 0.0853 - val_accuracy: 0.9807\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.0740 - val_accuracy: 0.9829\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.1027 - val_accuracy: 0.9810\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.1029 - val_accuracy: 0.9812\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.1105 - val_accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.1046 - val_accuracy: 0.9828\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.1046 - val_accuracy: 0.9813\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.1004 - val_accuracy: 0.9830\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.1131 - val_accuracy: 0.9809\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.1314 - val_accuracy: 0.9810\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.1041 - val_accuracy: 0.9855\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.1117 - val_accuracy: 0.9847\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.1300 - val_accuracy: 0.9816\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.1281 - val_accuracy: 0.9845\n",
      "Test loss:  0.12809915993566756\n",
      "Test accuracy:  0.984499990940094\n"
     ]
    }
   ],
   "source": [
    "# keras models are trained on Numpy arrays of input data and labels.\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=784))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                   batch_size = batch_size,\n",
    "                   epochs = epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
